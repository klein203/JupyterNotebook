{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.3 64-bit ('Miniconda3': conda)",
   "display_name": "Python 3.7.3 64-bit ('Miniconda3': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a72f68cc148b279a81ef0488079e33db58bd3e723d7638e46009e47145dcc430"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# CXJ\n",
    "## Key words\n",
    "association analysis, fp-growth, cxj\n",
    "## settings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyfpgrowth==1.0"
   ]
  },
  {
   "source": [
    "## preprocess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# column field definition\n",
    "REC_COL_DATE = \"日期\"\n",
    "REC_COL_PLATE = \"车牌\"\n",
    "REC_COL_S_CODE = \"S码\"\n",
    "\n",
    "# raw files\n",
    "raw_files = [\n",
    "    './data/CXJ_202001_03.csv',\n",
    "    './data/CXJ_202004_05.csv',\n",
    "    './data/CXJ_202006_07.csv',\n",
    "    './data/CXJ_202008_09.csv',\n",
    "]\n",
    "\n",
    "# files to save list of SCODE groups\n",
    "pkl_files = [\n",
    "    './data/CXJ_202001_03.pkl',\n",
    "    './data/CXJ_202004_05.pkl',\n",
    "    './data/CXJ_202006_07.pkl',\n",
    "    './data/CXJ_202008_09.pkl',\n",
    "]\n",
    "\n",
    "rules_pkl_file = './data/rules_freq500_202001_09.pkl'\n",
    "\n",
    "rules_txt_file = './data/rules_freq500_202001_09.txt'\n",
    "\n",
    "\n",
    "def save_to_pickle(file, trans, mode='wb'):\n",
    "    with open(file, mode) as f:\n",
    "        pickle.dump(trans, f)\n",
    "    print(\"file %s(%d) saved\" % (file, len(trans)))\n",
    "\n",
    "def load_from_pickle(file, mode='rb'):\n",
    "    with open(file, mode) as f:\n",
    "        trans = pickle.load(f)\n",
    "    print(\"file %s(%d) loaded\" % (file, len(trans)))\n",
    "    return trans\n",
    "\n",
    "def batch_save(from_files, to_files):\n",
    "    for from_file, to_file in zip(from_files, to_files):\n",
    "        trans = []\n",
    "        df = pd.read_csv(from_file, encoding=\"utf-8\")\n",
    "        df.groupby([REC_COL_DATE, REC_COL_PLATE]).apply(lambda x:trans.append(list(set(x[REC_COL_S_CODE]))))\n",
    "        save_to_pickle(to_file, trans)\n",
    "\n",
    "def batch_load(from_files):\n",
    "    trans = []\n",
    "    for from_file in from_files:\n",
    "        trans.extend(load_from_pickle(from_file))\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init service code dictionary\n",
    "import pandas\n",
    "\n",
    "DT_COL_S_CODE = \"服务编码\"\n",
    "DT_COL_S_NAME = \"服务名称\"\n",
    "\n",
    "def load_scode_dict(file):\n",
    "\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    dt = dict()\n",
    "\n",
    "    def foo(x):\n",
    "        dt[x[DT_COL_S_CODE]] = x[DT_COL_S_NAME]\n",
    "    \n",
    "    df.apply(foo, axis=1)\n",
    "    return dt\n",
    "\n",
    "scode_dict_file = \"./data/service_info.csv\"\n",
    "\n",
    "scode_dict = load_scode_dict(scode_dict_file)\n",
    "\n",
    "def fullname(scode):\n",
    "    return \"%s %s\" % (scode, scode_dict.get(scode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save rules from .pkl to .txt\n",
    "def save_rules(from_file, to_file, mode='a', l_limit=3):\n",
    "    rules = load_from_pickle(from_file)\n",
    "    with open(to_file, mode, encoding='utf-8') as f:\n",
    "        for rule in rules:\n",
    "            if len(rule) <= l_limit:\n",
    "                line = \"{}\\t=>\\t{}\\t{:.0%}\\n\".format(list(map(fullname, rule)), \\\n",
    "                    list(map(fullname, rules[rule][0])), rules[rule][1])\n",
    "                f.write(line)\n",
    "    print(\"file %s saved\" % to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract code list from raw records and save to pkl files\n",
    "batch_save(raw_files, pkl_files)"
   ]
  },
  {
   "source": [
    "## algo: fp-growth"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fp-tree\n",
    "import pyfpgrowth\n",
    "\n",
    "trans = batch_load(pkl_files)\n",
    "print(\"total size of transactions: %d\" % len(trans))\n",
    "\n",
    "# support frequency 500\n",
    "patterns = pyfpgrowth.find_frequent_patterns(trans, 500)\n",
    "\n",
    "# data mining with threholds of confidence 70%\n",
    "rules = pyfpgrowth.generate_association_rules(patterns, 0.7)\n",
    "\n",
    "# save rules to file\n",
    "save_to_pickle(rules_pkl_file, rules)"
   ]
  },
  {
   "source": [
    "## post process"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_rules(rules_pkl_file, rules_txt_file, l_limit=3)"
   ]
  },
  {
   "source": [
    "## Batch Example"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfpgrowth\n",
    "\n",
    "trans = batch_load(pkl_files)\n",
    "print(\"total size of transactions: %d\" % len(trans))\n",
    "\n",
    "# support frequency 500\n",
    "patterns = pyfpgrowth.find_frequent_patterns(trans, 500)\n",
    "\n",
    "# data mining with threholds of confidence 50%\n",
    "rules = pyfpgrowth.generate_association_rules(patterns, 0.5)\n",
    "\n",
    "# save rules to file\n",
    "save_to_pickle('./data/rules_freq500_202001_09.pkl', rules)\n",
    "save_rules('./data/rules_freq500_202001_09.pkl', './data/rules_freq500_202001_09.txt', l_limit=3)"
   ]
  }
 ]
}