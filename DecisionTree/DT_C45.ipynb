{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import logging\n",
    "import os\n",
    "import uuid\n",
    "import graphviz as gv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('DT_C45')\n",
    "column_property_dict = ['is_discrete']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    root = None\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "    \n",
    "    def print_tree(self):\n",
    "        if self.root == None:\n",
    "            return\n",
    "        else:\n",
    "            node = root.print_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    _uuid = None\n",
    "    _feature = None\n",
    "    _label = None\n",
    "    _is_discrete = None\n",
    "    _is_leaf = None\n",
    "    _child_nodes = None\n",
    "    _value = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return ('[%s, %s, %s, %s, %s, %s, %s]' % (self._id, self._feature, self._value, self._is_discrete, self._label, self._is_leaf, self._child_nodes.keys()))\n",
    "    \n",
    "    @property\n",
    "    def uuid(self):\n",
    "        return self._uuid\n",
    "    \n",
    "    @property\n",
    "    def label(self):\n",
    "        return self._label\n",
    "    \n",
    "    @label.setter\n",
    "    def label(self, value):\n",
    "        self._label = value\n",
    "\n",
    "    @property\n",
    "    def feature(self):\n",
    "        return self._feature\n",
    "    \n",
    "    @feature.setter\n",
    "    def feature(self, value):\n",
    "        self._feature = value\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        return self._value\n",
    "    \n",
    "    @value.setter\n",
    "    def value(self, value):\n",
    "        self._value = value\n",
    "\n",
    "    @property\n",
    "    def is_leaf(self):\n",
    "        return self._is_leaf\n",
    "    \n",
    "    @is_leaf.setter\n",
    "    def is_leaf(self, value):\n",
    "        self._is_leaf = value\n",
    "    \n",
    "    @property\n",
    "    def is_discrete(self):\n",
    "        return self._is_discrete\n",
    "    \n",
    "    @is_discrete.setter\n",
    "    def is_discrete(self, value):\n",
    "        self._is_discrete = value\n",
    "    \n",
    "    @property\n",
    "    def child_nodes(self):\n",
    "        return self._child_nodes\n",
    "\n",
    "    def add_child(self, op, op_value, child_node):\n",
    "        if self._is_discrete == True:\n",
    "            self._child_nodes[op+op_value] = child_node\n",
    "        elif self._is_discrete == False:\n",
    "            self._value = op_value\n",
    "            self._child_nodes[op] = child_node\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    def _check_arg(self, key, kwargs):\n",
    "        if key in kwargs:\n",
    "            return kwargs[key]\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        self._uuid = uuid.uuid4()\n",
    "        self._feature = self._check_arg('feature', kwargs)\n",
    "        self._is_discrete = self._check_arg('is_discrete', kwargs)\n",
    "        self._is_leaf = self._check_arg('is_leaf', kwargs)\n",
    "        self._label = self._check_arg('label', kwargs)\n",
    "        self._value = self._check_arg('value', kwargs)\n",
    "        self._child_nodes = {}\n",
    "    \n",
    "    def print_node(self):\n",
    "        if self._is_leaf:\n",
    "            logger.info('Label Node [%s]' % (self._label))\n",
    "        else:\n",
    "            for key in self._child_nodes.keys():\n",
    "                if self._child_nodes[key].is_discrete == True:\n",
    "                    logger.info('Decision Node [%s], [%s] >' % (self._feature, key))\n",
    "                else:\n",
    "                    logger.info('Decision Node [%s], [%s%s] >' % (self._feature, key, self._value))\n",
    "                self._child_nodes[key].print_node()\n",
    "    \n",
    "    def to_dot(self):\n",
    "        edges = []\n",
    "        if self._is_leaf:\n",
    "            return []\n",
    "        else:\n",
    "            if self._is_discrete == True:\n",
    "                for key in self._child_nodes.keys():\n",
    "                    if self._child_nodes[key].is_leaf == True:\n",
    "                        edges.append('\"Decision Node: %s\\n[%s]\" -> \"Label Node: %s\\n[%s]\"[label=\"%s\"];' % (self._feature, self._uuid, self._child_nodes[key].label, self._child_nodes[key].uuid, key))\n",
    "                    else:\n",
    "                        edges.append('\"Decision Node: %s\\n[%s]\" -> \"Decision Node: %s\\n[%s]\"[label=\"%s\"];' % (self._feature, self._uuid, self._child_nodes[key].feature, self._child_nodes[key].uuid, key))\n",
    "                    edges.extend(self._child_nodes[key].to_dot())\n",
    "            else:\n",
    "                for key in self._child_nodes.keys():\n",
    "                    if self._child_nodes[key].is_leaf == True:\n",
    "                        edges.append('\"Decision Node: %s\\n[%s]\" -> \"Label Node: %s\\n[%s]\"[label=\"%s\"];' % (self._feature, self._uuid, self._child_nodes[key].label, self._child_nodes[key].uuid, key+str(self._value)))\n",
    "                    else:\n",
    "                        edges.append('\"Decision Node: %s\\n[%s]\" -> \"Decision Node: %s\\n[%s]\"[label=\"%s\"];' % (self._feature, self._uuid, self._child_nodes[key].feature, self._child_nodes[key].uuid, key+str(self._value)))\n",
    "                    edges.extend(self._child_nodes[key].to_dot())\n",
    "        return edges\n",
    "    \n",
    "    def find_next_node(self, dataset, r_idx):\n",
    "        if self._is_leaf == True:\n",
    "            return None\n",
    "        else:\n",
    "            data = dataset.data\n",
    "            val = data[self._feature][r_idx]\n",
    "            if self._is_discrete == True:\n",
    "                return self._child_nodes['=='+val]\n",
    "            elif self._is_discrete == False:\n",
    "                # support continuous data\n",
    "                if val <= self._value:\n",
    "                    return self._child_nodes['<=']\n",
    "                else:\n",
    "                    return self._child_nodes['>']\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    _data = None\n",
    "    _column_properties = None\n",
    "    \n",
    "    def __init__(self, data, column_properties):\n",
    "        self._data = data\n",
    "        self._column_properties = column_properties\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._data\n",
    "    \n",
    "    @data.setter\n",
    "    def data(self, value):\n",
    "        self._data = value\n",
    "    \n",
    "    @property\n",
    "    def column_properties(self):\n",
    "        return self._column_properties\n",
    "    \n",
    "    @column_properties.setter\n",
    "    def column_properties(self, value):\n",
    "        self._column_properties = value\n",
    "    \n",
    "    def column_property(self, key):\n",
    "        return self._column_properties[key]\n",
    "\n",
    "    def column_property_val(self, key, feature):\n",
    "        return self._column_properties[key][feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    return load_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path=os.getcwd(), file='discrete_data.xlsx'):\n",
    "    data = pd.read_excel(os.path.join(path, file), sheet_name=0)\n",
    "    \n",
    "    col_data = pd.read_excel(os.path.join(path, file), sheet_name=1)\n",
    "    # skip 'column_property_dict' and 'label' columns\n",
    "    columns = col_data.columns[1:-1]\n",
    "    column_properties = {}\n",
    "    for r_idx, row in col_data.iterrows():\n",
    "        config = {}\n",
    "        for col in columns:\n",
    "            config[col] = row[col]\n",
    "        column_properties[column_property_dict[r_idx]] = config\n",
    "    return Dataset(data, column_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_iris(path=os.getcwd(), file='iris.data'):\n",
    "    data = pd.read_csv(os.path.join(path, file))\n",
    "    column_properties = {column_property_dict[0]: {'SepalLengthCm': False, \n",
    "                                         'SepalWidthCm': False, \n",
    "                                         'PetalLengthCm': False, \n",
    "                                         'PetalWidthCm': False, \n",
    "                                         'Species': True}}\n",
    "    return Dataset(data, column_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_dataset():\n",
    "    data = pd.DataFrame({'年龄':[25, 37], \n",
    "                         '年龄分类':['青年', '中年'], \n",
    "                         '有工作':['是', '是'], \n",
    "                         '有房子':['是', '是'], \n",
    "                         '信贷情况':['一般', '好'], \n",
    "                         '类别':['通过', '通过']})\n",
    "    column_properties = {column_property_dict[0]: {'年龄': False, \n",
    "                                          '年龄分类': True, \n",
    "                                          '有工作': True, \n",
    "                                          '有房子': True, \n",
    "                                          '信贷情况': True, \n",
    "                                          '类别': True}}\n",
    "    \n",
    "    return Dataset(data, column_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(dataset):\n",
    "    data = dataset.data\n",
    "    labels = data[data.columns[-1]]\n",
    "    m = len(data)\n",
    "\n",
    "    entropy = 0.\n",
    "#     logging.debug('y_labels:\\n%s' % labels.value_counts())\n",
    "    for _, cnt in labels.value_counts().items():\n",
    "        p = cnt / m\n",
    "        entropy += - p * math.log(p, 2)\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_feature(dataset):\n",
    "    data = dataset.data\n",
    "    columns = data.columns[:-1]\n",
    "    label = data.columns[-1]\n",
    "    m = len(data)\n",
    "    logging.debug('data:\\n%s' % data)\n",
    "    \n",
    "    base_entropy = calc_entropy(dataset)\n",
    "    info_gain_rate = 0.\n",
    "    best_feature = None\n",
    "    best_feature_val = None\n",
    "        \n",
    "    for feature in columns:\n",
    "        split_info = 0.\n",
    "        c_entropy = 0.\n",
    "        info_gain_rate_temp = 0.\n",
    "        split_point = None\n",
    "        \n",
    "        if dataset.column_property_val(column_property_dict[0], feature) == True:\n",
    "            # support discrete data\n",
    "            unique_feature_vals = data[feature].unique()\n",
    "            logging.debug('feature: %s, unique_val: %s' % (feature, unique_feature_vals))\n",
    "\n",
    "            for unique_feature_val in unique_feature_vals:\n",
    "                sub_data_temp = split_data(dataset, feature, None, unique_feature_val)\n",
    "                m_sub = len(sub_data_temp)\n",
    "                delta_c_entropy = m_sub / m * calc_entropy(sub_data_temp)\n",
    "                logging.debug('%s: %s, [%d/%d], delta_c_entropy: %.6f, sub_data:\\n%s' % (feature, unique_feature_val, m_sub, m, delta_c_entropy, sub_data_temp.data))\n",
    "                c_entropy += delta_c_entropy\n",
    "\n",
    "            logging.debug('feature: %s, total_c_entropy: %.6f' % (feature, c_entropy))\n",
    "\n",
    "            # calculate split info\n",
    "            for _, cnt in data[feature].value_counts().items():\n",
    "                p = cnt / m\n",
    "                split_info += - p * math.log(p, 2)\n",
    "        else:\n",
    "            # support continuous data\n",
    "            sorted_data = data.sort_values(feature, ascending=True)\n",
    "            unique_feature_vals = sorted_data[feature].unique()\n",
    "            if len(unique_feature_vals) < 2:\n",
    "                # c_entropy is zero, maxium info gain\n",
    "                return feature, unique_feature_vals[0]\n",
    "            elif len(unique_feature_vals) == 2:\n",
    "                discrete_points = [(unique_feature_vals[0] + unique_feature_vals[1]) / 2]\n",
    "            else:\n",
    "                discrete_points = (unique_feature_vals[0:-2] + unique_feature_vals[1:-1]) / 2\n",
    "                \n",
    "            # pick maxium of info gain\n",
    "            info_gain = 0.\n",
    "            l_p = 0.\n",
    "            r_p = 0.\n",
    "            for pt in discrete_points:\n",
    "                c_entropy = 0.\n",
    "\n",
    "                l_sub_data_temp = split_data(dataset, feature, '<=', pt)\n",
    "                m_l_sub = len(l_sub_data_temp)\n",
    "                delta_c_entropy = m_l_sub / m * calc_entropy(l_sub_data_temp)\n",
    "                logging.debug('%s: <=%s, [%d/%d], delta_c_entropy: %.6f, sub_data:\\n%s' % (feature, pt, m_l_sub, m, delta_c_entropy, l_sub_data_temp.data))\n",
    "                c_entropy += delta_c_entropy\n",
    "\n",
    "                r_sub_data_temp = split_data(dataset, feature, '>', pt)\n",
    "                m_r_sub = len(r_sub_data_temp)\n",
    "                delta_c_entropy = m_r_sub / m * calc_entropy(r_sub_data_temp)\n",
    "                logging.debug('%s: >%s, [%d/%d], delta_c_entropy: %.6f, sub_data:\\n%s' % (feature, pt, m_r_sub, m, delta_c_entropy, r_sub_data_temp.data))\n",
    "                c_entropy += delta_c_entropy\n",
    "\n",
    "                info_gain_temp = base_entropy - c_entropy\n",
    "                if info_gain_temp >= info_gain:\n",
    "                    split_point = pt\n",
    "                    info_gain = info_gain_temp\n",
    "                    l_p = m_l_sub / m\n",
    "                    r_p = m_r_sub / m\n",
    "                \n",
    "            # calculate split info\n",
    "            for p in [l_p, r_p]:\n",
    "                split_info += - p * math.log(p, 2)\n",
    "\n",
    "        # if p is 0/1, make split_info non-zero\n",
    "        if split_info == 0.0:\n",
    "            split_info = - 0.99 * math.log(0.99, 2) - 0.01 * math.log(0.01, 2)\n",
    "\n",
    "        # calculate info gain rate\n",
    "        info_gain_rate_temp = (base_entropy - c_entropy) / split_info\n",
    "        if info_gain_rate_temp > info_gain_rate:\n",
    "            logging.debug('feature: %s, split_point: %s, info_gain_rate_temp: %.6f' % (feature, split_point, info_gain_rate_temp))\n",
    "            info_gain_rate = info_gain_rate_temp\n",
    "            best_feature = feature\n",
    "            best_feature_val = split_point\n",
    "    \n",
    "    logging.info('best feature: %s, info gain rate: %.6f' % (best_feature, info_gain_rate))\n",
    "    \n",
    "    return best_feature, best_feature_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset, feature, op, value):\n",
    "    data = dataset.data\n",
    "    sub_data_temp = None\n",
    "    if dataset.column_property_val(column_property_dict[0], feature) == True:\n",
    "        sub_data_temp = data[data[feature] == value].copy()\n",
    "    else:\n",
    "        if op == '<=':\n",
    "            sub_data_temp = data[data[feature] <= value].copy()\n",
    "        elif op == '>':\n",
    "            sub_data_temp = data[data[feature] > value].copy()\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    sub_data_temp.drop(feature, axis=1, inplace=True)\n",
    "    return Dataset(sub_data_temp, dataset.column_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def major_label(labels):\n",
    "    value_counts = labels.value_counts().sort_values(ascending=False)\n",
    "    logging.info('label conflict exists:\\n%s' % (value_counts))\n",
    "    return value_counts.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(dataset):\n",
    "    data = dataset.data\n",
    "    labels = data[data.columns[-1]]\n",
    "    unique_labels = labels.unique()\n",
    "    \n",
    "    # if only one unique label left, just pick this label\n",
    "    if len(unique_labels) == 1:\n",
    "        return Node(**{'label': unique_labels[0], \n",
    "                       'is_leaf': True})\n",
    "    \n",
    "    # if some conflicts on labels with same input, pick the label with highest probability\n",
    "    if len(data.columns) == 1:\n",
    "        return Node(**{'label': major_label(labels), \n",
    "                       'is_leaf': True})\n",
    "    \n",
    "    best_feature, best_feature_val = choose_best_feature(dataset)\n",
    "    node = Node(**{'feature': best_feature, \n",
    "                   'is_discrete': dataset.column_property_val(column_property_dict[0], best_feature), \n",
    "                   'is_leaf': False})\n",
    "                \n",
    "    if dataset.column_property_val(column_property_dict[0], best_feature) == True:\n",
    "        unique_feature_vals = data[best_feature].unique()\n",
    "        for val in unique_feature_vals:\n",
    "            sub_data = split_data(dataset, best_feature, None, val)\n",
    "            child = create_tree(sub_data)\n",
    "            node.add_child('==', val, child)\n",
    "    else:\n",
    "        l_sub_data = split_data(dataset, best_feature, '<=', best_feature_val)\n",
    "        l_child = create_tree(l_sub_data)\n",
    "        node.add_child('<=', best_feature_val, l_child)\n",
    "        \n",
    "        r_sub_data = split_data(dataset, best_feature, '>', best_feature_val)\n",
    "        r_child = create_tree(r_sub_data)\n",
    "        node.add_child('>', best_feature_val, r_child)\n",
    "    \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating(model, dataset):\n",
    "    data = dataset.data\n",
    "    labels = data[data.columns[-1]]\n",
    "    m = len(data)\n",
    "    \n",
    "    pred_data = pd.DataFrame()\n",
    "    for r_idx, _ in data.iterrows():\n",
    "        node = model\n",
    "        while True:\n",
    "            if node.is_leaf:\n",
    "                pred_data = pred_data.append(pd.DataFrame({'pred_labels': [node.label]}), ignore_index=True)\n",
    "                break\n",
    "            node = node.find_next_node(dataset, r_idx)\n",
    "    \n",
    "    results = pred_data[pred_data['pred_labels'] == labels]\n",
    "    rating = len(results) / m\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_graph(root):\n",
    "    edge_data = ''\n",
    "    edges = root.to_dot()\n",
    "    for edge in edges:\n",
    "        edge_data += edge\n",
    "    dot_data = 'digraph edge_settings {%s}' % edge_data\n",
    "    graph = gv.Source(dot_data)\n",
    "    graph.render()\n",
    "    logging.info('generate graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-70-fe6f03b8bda6>[11] - base entropy: 0.9709505944546686\n",
      "<ipython-input-59-9966f5fbb6e6>[91] - best feature: 有房子, info gain rate: 0.432538\n",
      "<ipython-input-59-9966f5fbb6e6>[91] - best feature: 有工作, info gain rate: 1.000000\n",
      "<ipython-input-68-00b3d37e2b13>[91] - Decision Node [有房子], [==否] >\n",
      "<ipython-input-68-00b3d37e2b13>[93] - Decision Node [有工作], [==否None] >\n",
      "<ipython-input-68-00b3d37e2b13>[87] - Label Node [不通过]\n",
      "<ipython-input-68-00b3d37e2b13>[93] - Decision Node [有工作], [==是None] >\n",
      "<ipython-input-68-00b3d37e2b13>[87] - Label Node [通过]\n",
      "<ipython-input-68-00b3d37e2b13>[93] - Decision Node [有房子], [==是None] >\n",
      "<ipython-input-68-00b3d37e2b13>[87] - Label Node [通过]\n",
      "<ipython-input-70-fe6f03b8bda6>[23] - verify rating: 100.00%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # logging setting\n",
    "#     logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s')\n",
    "    logging.basicConfig(level=logging.INFO, format='%(filename)s[%(lineno)d] - %(message)s')\n",
    "    \n",
    "    \n",
    "    # model train\n",
    "#     dataset = load_dataset()\n",
    "    dataset = load_iris()\n",
    "    base_entropy = calc_entropy(dataset)\n",
    "    logging.info('base entropy: %s' % base_entropy)\n",
    "    \n",
    "    root = create_tree(dataset)\n",
    "    root.print_node()\n",
    "#     logging.info('model: %s' % root)\n",
    "\n",
    "    # graph\n",
    "#     gen_graph(root)\n",
    "    \n",
    "    # verify\n",
    "    verify_data = dataset\n",
    "    verify_ratings = rating(root, verify_data)\n",
    "    logging.info('verify rating: %.2f%%' % (verify_ratings * 100))\n",
    "    \n",
    "    # test\n",
    "#     test_data = load_test_dataset()\n",
    "#     ratings = fit(root, test_data)\n",
    "    \n",
    "#     logging.debug('test_data:\\n%s' % test_data.data)\n",
    "#     logging.info('rating: %.2f%%' % (ratings * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
