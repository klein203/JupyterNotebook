{
 "cells": [
  {
   "source": [
    "# PD881\n",
    "## settings\n",
    "## raw data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 文件位置定义\n",
    "file_col_def = './data/PD881_Column_Definition_20201014.xlsx'\n",
    "file_raw_data = './data/PD881_raw.xlsx'\n",
    "file_data = './data/PD881_data.xlsx'\n",
    "\n",
    "COL_IDX = \"NIDonly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列名信息\n",
    "df_col_def = pd.read_excel(file_col_def)\n",
    "# col_def = df_col_def[df_col_def['SPSS数据保留']==1]['英文描述'].to_list()\n",
    "col_def = df_col_def[df_col_def['数据分析保留']==1]['英文描述'].to_list()\n",
    "# col_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原数据初过滤列，生成初始数据\n",
    "df_raw_data = pd.read_excel(file_raw_data, index_col=COL_IDX)\n",
    "df = df_raw_data[col_def]\n",
    "df.to_excel(file_data)\n",
    "del df_raw_data"
   ]
  },
  {
   "source": [
    "## preprocessing\n",
    "### load file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "file_col_def = './data/PD881_Column_Definition_20201014.xlsx'\n",
    "file_data = './data/PD881_data.xlsx'\n",
    "COL_IDX = \"NIDonly\"\n",
    "\n",
    "df = pd.read_excel(file_data, index_col=COL_IDX)"
   ]
  },
  {
   "source": [
    "### EDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索性分析\n",
    "df.describe(include=\"all\").to_excel('./temp/df_describe.xlsx')"
   ]
  },
  {
   "source": [
    "### rename columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.rename(columns={\n",
    "#     'ori_col_name': 'new_col_name',\n",
    "# })"
   ]
  },
  {
   "source": [
    "### special rules"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column familyhis\n",
    "def familyhis_replace_rule(x):\n",
    "    if x.values[0] == \",\":\n",
    "        return np.nan\n",
    "    elif x.values[0] == \",无,\":\n",
    "        return \"无\"\n",
    "    else:\n",
    "        return \"是\"\n",
    "\n",
    "df[[\"familyhis\"]] = df[[\"familyhis\"]].apply(familyhis_replace_rule, axis=1)\n",
    "\n",
    "# df.loc[:, \"familyhis\"] = df[[\"familyhis\"]].apply(familyhis_replace_rule, axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column V0_DIAG_HY\n",
    "# 五分类 -> 十分类\n",
    "df[[\"V0_DIAG_HY\"]] = df[[\"V0_DIAG_HY\"]].apply(lambda x: 2 * x)"
   ]
  },
  {
   "source": [
    "### encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定类列名信息（离散）\n",
    "df_col_def = pd.read_excel(file_col_def)\n",
    "col_discrete_def = \\\n",
    "    df_col_def[(df_col_def[\"数据分析保留\"]==1)&(df_col_def[\"数据类型\"]==\"定类\")][\"英文描述\"].to_list()\n",
    "# col_discrete_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 离散数据序数编码器\n",
    "ordinal_enc_dict = {}\n",
    "for col_name in col_discrete_def:\n",
    "    # Create Ordinal encoder for col\n",
    "    ordinal_enc_dict[col_name] = OrdinalEncoder(dtype=\"int64\")\n",
    "    col = df[col_name]\n",
    "    \n",
    "    # Select non-null values of col\n",
    "    col_not_null = col[col.notnull()]\n",
    "    reshaped_vals = col_not_null.values.reshape(-1, 1)\n",
    "    encoded_vals = ordinal_enc_dict[col_name].fit_transform(reshaped_vals)\n",
    "    \n",
    "    # Store the values to non-null values of the column in users\n",
    "    df.loc[col.notnull(), col_name] = np.squeeze(encoded_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 离散数据编码映射\n",
    "{key: val.categories_[0].tolist() for key, val in ordinal_enc_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "df.to_excel('./temp/df_temp.xlsx')"
   ]
  },
  {
   "source": [
    "### check missing values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load init data\n",
    "print(\"1. Load file\", file_data)\n",
    "df = pd.read_excel(file_data, index_col=COL_IDX)\n",
    "\n",
    "# check missing values\n",
    "print(\"2. Check missing values\")\n",
    "print(\"2-1. Index - Missing values detected:\", df.index.isna().any())\n",
    "\n",
    "col_missing_values = df.columns[df.isna().any().values==True].tolist()\n",
    "print(\"2-2. Columns - Missing values detected:\", len(col_missing_values)>0)\n",
    "print(col_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in ordinal_enc_dict.values():\n",
    "    print(val.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc = OrdinalEncoder()\n",
    "# X = df[]\n",
    "# X.fillna()\n",
    "# X = enc.fit_transform(X)\n",
    "# enc.categories_\n",
    "\n",
    "# df[[\"sex\", \"PMH_HEADTRAUMA\"]].replace(enc.categories_, inplace=True)\n",
    "# df[[\"sex\", \"PMH_HEADTRAUMA\"]]\n",
    "# enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(col_def) - set(col_missing_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NTIMES = 5\n",
    "\n",
    "# all feature names\n",
    "all_feature_names = raw_data.columns\n",
    "\n",
    "# ext feature names\n",
    "ext_feature_names = [name[:-2] for name in all_feature_names if name.endswith('v0')]\n",
    "\n",
    "# base feature names\n",
    "base_feature_names = set(all_feature_names)\n",
    "for i in range(MAX_NTIMES):\n",
    "    base_feature_names -= set([name for name in all_feature_names if name.endswith('v'+str(i))])\n",
    "\n",
    "base_feature_names = list(base_feature_names)\n",
    "\n",
    "# additional feature name\n",
    "ntimes_feature_name = 'visit_time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_feature_names = base_feature_names + ext_feature_names + [ntimes_feature_name]\n",
    "trans_data = pd.DataFrame(columns=trans_feature_names, copy=True)\n",
    "\n",
    "raw_ext_feature_names_dict = {}\n",
    "for i in range(MAX_NTIMES):\n",
    "    raw_ext_feature_names_dict[i] = {name+'v'+str(i): name for name in ext_feature_names}\n",
    "    \n",
    "# iterate raw_data set\n",
    "for index, row in raw_data.iterrows():\n",
    "    for i in range(MAX_NTIMES):\n",
    "        # generate a dict like 'updrsv0': 'updrsv'\n",
    "#         raw_ext_feature_names_dict = {name+'v'+str(i): name for name in ext_feature_names}\n",
    "#         print(raw_ext_feature_names_dict)\n",
    "        raw_ext_feature_names = list(raw_ext_feature_names_dict[i].keys())\n",
    "\n",
    "        # new row\n",
    "        row_data = row[base_feature_names + raw_ext_feature_names]\n",
    "        row_data[ntimes_feature_name] = i\n",
    "        \n",
    "        # rename 'updrsv0' to 'updrs'\n",
    "        row_data.rename(index=raw_ext_feature_names_dict[i], inplace=True)\n",
    "\n",
    "        trans_data = trans_data.append([row_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_data.to_csv('./data/data_1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}