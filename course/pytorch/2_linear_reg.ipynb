{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt5\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "# sample: y = 0.447 * x + 1.241\n",
    "def sample_generator(n_sample=200):\n",
    "    sample_x = (torch.randn(n_sample, 1)) * 3\n",
    "    sample_y = 0.447 * sample_x + (1 + torch.randn(n_sample, 1)) * 1.241\n",
    "    return sample_x, sample_y\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    n_sample = 100\n",
    "    x, y  = sample_generator(n_sample)\n",
    "    w = torch.randn((1, 1), requires_grad=True)\n",
    "    b = torch.randn((1, 1), requires_grad=True)\n",
    "\n",
    "    fig = plt.figure(\"Linear Regression (Dynamic)\")\n",
    "    plt.ion()\n",
    "    \n",
    "    n_epoch = 1000\n",
    "    i_epoch = 0\n",
    "    lr = 1e-5\n",
    "    loss_hist = torch.zeros(n_epoch)\n",
    "    while i_epoch < n_epoch:\n",
    "        y_pred = x@w + b\n",
    "        loss = (y - y_pred).pow(2).sum()\n",
    "        loss_hist = loss_hist.index_fill(0, torch.tensor(i_epoch), loss.data.item())\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            w += - lr * w.grad\n",
    "            b += - lr * b.grad\n",
    "            w.grad.zero_()\n",
    "            b.grad.zero_()\n",
    "\n",
    "        if i_epoch % 5 == 0 or i_epoch == n_epoch - 1:\n",
    "            display.clear_output(wait=True)\n",
    "            plt.clf()\n",
    "\n",
    "            # visualization axes\n",
    "            ax0 = fig.add_subplot(211)\n",
    "            ax0.set_title(\"epoch [%d/%d], lr = %.5f\" % (i_epoch + 1, n_epoch, lr), size=10)\n",
    "            ax0.set_xlim(-12., 12.)\n",
    "            ax0.set_ylim(-8., 8.)\n",
    "\n",
    "            ax0.scatter(x.numpy(), y.numpy(), marker='.', color='b')\n",
    "\n",
    "            x_ori = torch.linspace(-10, 10, 100)\n",
    "            y_ori = x_ori * 0.447 + 1.241\n",
    "            ax0.plot(x_ori, y_ori, color='b')\n",
    "\n",
    "            x_model = torch.linspace(-10, 10, 100)\n",
    "            y_model = x_model * w.data.item() + b.data.item()\n",
    "            ax0.plot(x_model, y_model, color='r')\n",
    "            \n",
    "            # loss axes\n",
    "            ax1 = fig.add_subplot(212)\n",
    "            ax1.set_title(\"mse_loss = %.6f\" % loss, size=10)\n",
    "            ax1.set_xlim(0, n_epoch)\n",
    "            ax1.set_ylim(0, 1000)\n",
    "\n",
    "            x_loss = torch.arange(0, i_epoch)\n",
    "            y_loss = loss_hist.numpy()[0:i_epoch]\n",
    "            ax1.plot(x_loss, y_loss)\n",
    "\n",
    "            fig.tight_layout(pad=1.0, h_pad=1.0)\n",
    "            plt.pause(0.02)\n",
    "        \n",
    "        i_epoch += 1\n",
    "\n",
    "    plt.ioff()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d929303d4680d925cabe03ec42160f6384df453aa381528223735ccd71a7f366"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('py38_sci': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
