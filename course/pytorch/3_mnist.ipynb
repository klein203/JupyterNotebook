{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.177257902920246, 5.064475622028112, 4.094593511894345, 3.5508006773889065, 3.183746946975589, 2.9241901338100433, 2.7209360878914595, 2.5563995204865932, 2.422335173934698, 2.310547461733222]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt5\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "def plot_image(n_img=4, batch_size=512):\n",
    "    idx = np.random.randint(0, batch_size - 1, n_img)\n",
    "\n",
    "    fig, ax = plt.subplots(1, n_img)\n",
    "    for i in range(n_img):\n",
    "        img = Image.fromarray(x[idx[i]].squeeze().numpy() * 255)\n",
    "        ax[i].set_title(\"label %d\" % y[idx[i]].data.item(), size=10, )\n",
    "        ax[i].set_axis_off()\n",
    "        ax[i].imshow(img)\n",
    "\n",
    "    fig.tight_layout(pad=1.0, w_pad=1.0, h_pad=1.0)\n",
    "    plt.show()\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(28 * 28, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, 64)\n",
    "        self.fc3 = torch.nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    batch_size = 512\n",
    "    train_loader = torch.utils.data.dataloader.DataLoader(\n",
    "        torchvision.datasets.MNIST('mnist_data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    valid_loader = torch.utils.data.dataloader.DataLoader(\n",
    "        torchvision.datasets.MNIST('mnist_data', train=False, download=True, transform=torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # x, y = next(iter(train_loader))\n",
    "    # plot_image(10, batch_size)\n",
    "    \n",
    "    device = torch.device('cuda')\n",
    "\n",
    "    net = Net()\n",
    "    net.to(device)\n",
    "    lr = 1e-2\n",
    "    momentum = 0.9\n",
    "    optim = torch.optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    train_total_loss = []\n",
    "\n",
    "    n_epoch = 10\n",
    "    for epoch in range(n_epoch):\n",
    "        total_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            x = x.reshape(-1, 28 * 28)\n",
    "            y_onehot = torch.nn.functional.one_hot(y, num_classes=10)\n",
    "            y_onehot = y_onehot.type_as(x)\n",
    "            # loss = mse(y - y_pred)\n",
    "            loss = torch.nn.functional.mse_loss(net(x), y_onehot)\n",
    "            total_loss += loss.item()\n",
    "            # calculate grad\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            # w' = w - lr * grad\n",
    "            optim.step()\n",
    "        train_total_loss.append(total_loss)\n",
    "    \n",
    "    print(train_total_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for x, y in valid_loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    x = x.reshape(-1, 28 * 28)\n",
    "    y_onehot = torch.nn.functional.one_hot(y, num_classes=10)\n",
    "    y_onehot = y_onehot.type_as(x)\n",
    "    loss = torch.nn.functional.mse_loss(net(x), y_onehot)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
      "        4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
      "        4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4, 6, 4, 3, 0, 7, 0,\n",
      "        2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 4,\n",
      "        1, 7, 6, 9, 6, 0, 5, 4, 9, 9, 2, 1, 9, 4, 8, 7, 3, 9, 7, 4, 4, 4, 9, 2,\n",
      "        5, 4, 7, 6, 7, 9, 0, 5, 8, 5, 6, 6, 5, 7, 8, 1, 0, 1, 6, 4, 6, 7, 3, 1,\n",
      "        7, 1, 8, 2, 0, 2, 9, 9, 5, 5, 1, 5, 6, 0, 3, 4, 4, 6, 5, 4, 6, 5, 4, 5,\n",
      "        1, 4, 4, 7, 2, 3, 2, 7, 1, 8, 1, 8, 1, 8, 5, 0, 8, 9, 2, 5, 0, 1, 1, 1,\n",
      "        0, 9, 0, 3, 1, 6, 4, 2, 3, 6, 1, 1, 1, 3, 9, 5, 2, 9, 4, 5, 9, 3, 9, 0,\n",
      "        3, 6, 5, 5, 7, 2, 2, 7, 1, 2, 8, 4, 1, 7, 3, 3, 8, 8, 7, 9, 2, 2, 4, 1,\n",
      "        5, 9, 8, 7, 2, 3, 0, 4, 4, 2, 4, 1, 9, 5, 7, 7, 2, 8, 2, 6, 8, 5, 7, 7,\n",
      "        9, 1, 8, 1, 8, 0, 3, 0, 1, 9, 9, 4, 1, 8, 2, 1, 2, 9, 7, 5, 9, 2, 6, 4,\n",
      "        1, 5, 8, 2, 9, 2, 0, 4, 0, 0, 2, 8, 4, 7, 1, 2, 4, 0, 2, 7, 4, 3, 3, 0,\n",
      "        0, 3, 1, 9, 6, 5, 2, 5, 9, 2, 9, 3, 0, 4, 2, 0, 7, 1, 1, 2, 1, 5, 3, 3,\n",
      "        9, 7, 8, 6, 5, 6, 1, 3, 8, 1, 0, 5, 1, 3, 1, 5, 5, 6, 1, 8, 5, 1, 7, 9,\n",
      "        4, 6, 2, 2, 5, 0, 6, 5, 6, 3, 7, 2, 0, 8, 8, 5, 4, 1, 1, 4, 0, 3, 3, 7,\n",
      "        6, 1, 6, 2, 1, 9, 2, 8, 6, 1, 9, 5, 2, 5, 4, 4, 2, 8, 3, 8, 2, 4, 5, 0,\n",
      "        3, 1, 7, 7, 5, 7, 9, 7, 1, 9, 2, 1, 4, 2, 9, 2, 0, 4, 9, 1, 4, 8, 1, 8,\n",
      "        4, 5, 9, 8, 8, 3, 7, 6, 0, 0, 3, 0, 2, 6, 6, 4, 9, 3, 3, 3, 2, 3, 9, 1,\n",
      "        2, 6, 8, 0, 5, 6, 6, 6, 3, 8, 8, 2, 7, 5, 8, 9, 6, 1, 8, 4, 1, 2, 5, 9,\n",
      "        1, 9, 7, 5, 4, 0, 8, 9, 9, 1, 0, 5, 2, 3, 7, 8, 9, 4, 0, 6, 3, 9, 5, 2,\n",
      "        1, 3, 1, 3, 6, 5, 7, 4], device='cuda:0')\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 6, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
      "        4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
      "        4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4, 6, 4, 3, 0, 7, 0,\n",
      "        2, 7, 1, 7, 3, 7, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 4,\n",
      "        1, 7, 6, 9, 6, 0, 5, 4, 9, 9, 2, 1, 9, 4, 8, 7, 3, 9, 7, 4, 4, 4, 9, 2,\n",
      "        5, 4, 7, 6, 4, 9, 0, 5, 8, 5, 6, 6, 5, 7, 8, 1, 0, 1, 6, 4, 6, 7, 3, 1,\n",
      "        7, 1, 8, 2, 0, 9, 9, 9, 5, 5, 1, 5, 6, 0, 3, 4, 4, 6, 5, 4, 6, 5, 4, 5,\n",
      "        1, 4, 4, 7, 2, 3, 2, 7, 1, 8, 1, 8, 1, 8, 5, 0, 8, 9, 2, 5, 0, 1, 1, 1,\n",
      "        0, 9, 0, 5, 1, 6, 4, 2, 3, 6, 1, 1, 1, 3, 9, 5, 2, 9, 4, 5, 9, 3, 9, 0,\n",
      "        3, 5, 5, 5, 7, 2, 2, 7, 1, 2, 8, 4, 1, 7, 3, 3, 8, 7, 7, 9, 2, 2, 4, 1,\n",
      "        5, 8, 8, 4, 2, 3, 0, 2, 4, 2, 4, 1, 9, 5, 7, 7, 2, 8, 2, 0, 8, 5, 7, 7,\n",
      "        9, 1, 8, 1, 8, 0, 3, 0, 1, 9, 9, 4, 1, 8, 2, 1, 2, 9, 7, 5, 9, 2, 6, 4,\n",
      "        1, 5, 4, 2, 9, 2, 0, 4, 0, 0, 2, 8, 1, 7, 1, 2, 4, 0, 2, 7, 4, 3, 3, 0,\n",
      "        0, 5, 1, 9, 6, 5, 3, 5, 1, 7, 9, 3, 0, 4, 2, 0, 7, 1, 1, 2, 1, 5, 3, 3,\n",
      "        9, 7, 8, 6, 3, 6, 1, 3, 8, 1, 0, 5, 1, 7, 1, 5, 0, 6, 1, 8, 5, 1, 7, 9,\n",
      "        4, 6, 7, 2, 5, 0, 6, 5, 6, 3, 7, 2, 0, 8, 8, 5, 4, 1, 1, 4, 0, 7, 3, 7,\n",
      "        6, 1, 6, 2, 1, 9, 2, 8, 6, 1, 9, 5, 2, 5, 4, 4, 2, 8, 3, 5, 2, 4, 5, 0,\n",
      "        3, 1, 7, 7, 5, 7, 9, 7, 1, 9, 2, 1, 4, 2, 9, 2, 0, 4, 9, 1, 4, 8, 1, 8,\n",
      "        4, 4, 9, 8, 8, 3, 7, 6, 0, 0, 3, 0, 8, 0, 6, 4, 8, 5, 3, 3, 2, 3, 9, 1,\n",
      "        2, 6, 8, 0, 5, 6, 6, 6, 7, 8, 8, 2, 7, 5, 8, 9, 6, 1, 8, 4, 1, 2, 8, 3,\n",
      "        1, 9, 7, 7, 4, 0, 8, 9, 9, 1, 0, 5, 2, 3, 7, 8, 9, 4, 0, 6, 3, 9, 3, 2,\n",
      "        1, 3, 1, 5, 6, 5, 7, 4], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(valid_loader))\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "x = x.reshape(-1, 28 * 28)\n",
    "y_onehot = torch.nn.functional.one_hot(y, num_classes=10)\n",
    "y_onehot = y_onehot.type_as(x)\n",
    "y_pred = torch.argmax(net(x), -1)\n",
    "print(torch.argmax(y_onehot, -1))\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d929303d4680d925cabe03ec42160f6384df453aa381528223735ccd71a7f366"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('py38_sci': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
